{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import time\n",
    "# from tflite_micro_runtime.interpreter import Interpreter as tflm_Interpreter\n",
    "tflm_Interpreter = tf.lite.Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model_path = '../model_export/q-int8_d-2bit-octree.tflite'\n",
    "interpreter = tflm_Interpreter(tf_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "data_path = '../data/1bit-otsu/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "\n",
    "input_tensor_index = input_details[\"index\"]\n",
    "output = interpreter.get_tensor(output_details[\"index\"])\n",
    "\n",
    "mse = 0.0\n",
    "avg_cosine_similarity = 0.0\n",
    "num_examples = 100\n",
    "# it = iter(val_dataset.batch(1).take(num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for file in os.listdir(data_path):\n",
    "\tinput_data = Image.open(os.path.join(data_path, file))\n",
    "\tinput_data = np.array(input_data)\n",
    "\tinput_data = np.expand_dims(input_data, axis=0)\n",
    "\tinput_data = np.expand_dims(input_data, axis=-1)\n",
    "\n",
    "\tif (input_scale, input_zero_point) != (0.0, 0):\n",
    "\t\tinput_data = np.multiply(input_data, 1.0 / input_scale) + input_zero_point\n",
    "\tinput_data = input_data.astype(input_details[\"dtype\"])\n",
    "\timages.append(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time:  1.1477057933807373\n",
      "time per image:  0.02086737806146795\n",
      "hertz:  47.92168891819336\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for img_array in images:\n",
    "\n",
    "\tinput_scale, input_zero_point = input_details[\"quantization\"]\n",
    "\tif (input_scale, input_zero_point) != (0.0, 0):\n",
    "\t\timg_array = np.multiply(img_array, 1.0 / input_scale) + input_zero_point\n",
    "\timg_array = img_array.astype(input_details[\"dtype\"])\n",
    "\n",
    "\tinterpreter.set_tensor(input_tensor_index, img_array)\n",
    "\tinterpreter.invoke()\n",
    "\tpred = output[0]\n",
    "\n",
    "\n",
    "\t# If required, dequantized the output layer (from integer to float)\n",
    "\toutput_scale, output_zero_point = output_details[\"quantization\"]\n",
    "\tif (output_scale, output_zero_point) != (0.0, 0):\n",
    "\t\tpred = pred.astype(np.float32)\n",
    "\t\tpred = np.multiply((pred - output_zero_point), output_scale)\n",
    "\n",
    "\t# Compute cosine similarity.\n",
    "\ty_pred = pred.astype(np.float32)\n",
    "\t# print(output, pred)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print('elapsed time: ', elapsed)\n",
    "print('time per image: ', elapsed/len(images))\n",
    "print('hertz: ', len(images)/elapsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
